<!doctype html>
<html class="docs-version-current" lang="en" dir="ltr">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width,initial-scale=1">
<meta name="generator" content="Docusaurus v2.0.0-beta.15">
<title data-react-helmet="true">Training and results | ML4Sim</title><meta data-react-helmet="true" name="twitter:card" content="summary_large_image"><meta data-react-helmet="true" property="og:url" content="https://your-docusaurus-test-site.com/docs/ML_Model/training"><meta data-react-helmet="true" name="docusaurus_locale" content="en"><meta data-react-helmet="true" name="docusaurus_version" content="current"><meta data-react-helmet="true" name="docusaurus_tag" content="docs-default-current"><meta data-react-helmet="true" property="og:title" content="Training and results | ML4Sim"><meta data-react-helmet="true" name="description" content="This page summarizes the main VAE trainings and validations starting from a single geometry and energy conditioning towards building a generalizale and reusable VAE model."><meta data-react-helmet="true" property="og:description" content="This page summarizes the main VAE trainings and validations starting from a single geometry and energy conditioning towards building a generalizale and reusable VAE model."><link data-react-helmet="true" rel="icon" href="/img/favicon.ico"><link data-react-helmet="true" rel="canonical" href="https://your-docusaurus-test-site.com/docs/ML_Model/training"><link data-react-helmet="true" rel="alternate" href="https://your-docusaurus-test-site.com/docs/ML_Model/training" hreflang="en"><link data-react-helmet="true" rel="alternate" href="https://your-docusaurus-test-site.com/docs/ML_Model/training" hreflang="x-default"><link rel="stylesheet" href="/assets/css/styles.7069df34.css">
<link rel="preload" href="/assets/js/runtime~main.71701159.js" as="script">
<link rel="preload" href="/assets/js/main.f9c432a9.js" as="script">
</head>
<body>
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){var t=null;try{t=localStorage.getItem("theme")}catch(t){}return t}();t(null!==e?e:"light")}()</script><div id="__docusaurus">
<div role="region"><a href="#" class="skipToContent_ZgBM">Skip to main content</a></div><nav class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Navigation bar toggle" class="navbar__toggle clean-btn" type="button" tabindex="0"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><div class="navbar__logo"><img src="/img/logo.png" alt="Logo" class="themedImage_W2Cr themedImage--light_TfLj"><img src="/img/logo.png" alt="Logo" class="themedImage_W2Cr themedImage--dark_oUvU"></div><b class="navbar__title">ML4Sim</b></a><a class="navbar__item navbar__link navbar__link--active" href="/docs/intro">Get started</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/DalilaSalamani/ML4Sim_Documentation.git" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a><div class="toggle_Pssr toggle_TdHA toggleDisabled_jDku"><div class="toggleTrack_SSoT" role="button" tabindex="-1"><div class="toggleTrackCheck_XobZ"><span class="toggleIcon_eZtF">ðŸŒœ</span></div><div class="toggleTrackX_YkSC"><span class="toggleIcon_eZtF">ðŸŒž</span></div><div class="toggleTrackThumb_uRm4"></div></div><input type="checkbox" class="toggleScreenReader_JnkT" aria-label="Switch between dark and light mode"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div class="main-wrapper docs-wrapper docs-doc-page"><div class="docPage_P2Lg"><button aria-label="Scroll back to top" class="clean-btn theme-back-to-top-button backToTopButton_RiI4" type="button"></button><aside class="theme-doc-sidebar-container docSidebarContainer_rKC_"><div class="sidebar_CW9Y"><nav class="menu thin-scrollbar menu_SkdO"><ul class="theme-doc-sidebar-menu menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/intro">Full and fast simulation</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/ml_fastsim">Generative modeling</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-1 menu__list-item"><a class="menu__link" href="/docs/ml_workflow">Machine learning workflow</a></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist menu__link--active hasHref_VCh3" aria-current="page" href="/docs/ML_Model/training">Generative models for fast simulation</a></div><ul style="display:block;overflow:visible;height:auto" class="menu__list"><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link menu__link--active" aria-current="page" tabindex="0" href="/docs/ML_Model/training">Training and results</a></li><li class="theme-doc-sidebar-item-link theme-doc-sidebar-item-link-level-2 menu__list-item"><a class="menu__link" tabindex="0" href="/docs/ML_Model/optimization">Model optimization</a></li></ul></li><li class="theme-doc-sidebar-item-category theme-doc-sidebar-item-category-level-1 menu__list-item menu__list-item--collapsed"><div class="menu__list-item-collapsible"><a class="menu__link menu__link--sublist hasHref_VCh3" href="/docs/G4_Inference/from_training_to_inference">Inference integration in Geant4</a></div></li></ul></nav></div></aside><main class="docMainContainer_TCnq"><div class="container padding-top--md padding-bottom--lg"><div class="row"><div class="col docItemCol_DM6M"><div class="docItemContainer_vinB"><article><div class="tocCollapsible_jdIR theme-doc-toc-mobile tocMobile_TmEX"><button type="button" class="clean-btn tocCollapsibleButton_Fzxq">On this page</button></div><div class="theme-doc-markdown markdown"><h1>Training and results</h1><p>This page summarizes the main VAE trainings and validations starting from a single geometry and energy conditioning towards building a generalizale and reusable VAE model. </p><h2 class="anchor anchorWithStickyNavbar_mojV" id="single-geometry">Single geometry<a class="hash-link" href="#single-geometry" title="Direct link to heading">â€‹</a></h2><h3 class="anchor anchorWithStickyNavbar_mojV" id="energy-conditioning">Energy conditioning<a class="hash-link" href="#energy-conditioning" title="Direct link to heading">â€‹</a></h3><p>Simulating showers using FastV started with investigating and exploring the performance on a single calorimeter geometry. The VAE model is trained on eletron particle showers. The detector considered is a homogeneous cylinder of lead (PBWO4). It is segmented along <strong>(r,<!-- -->Ï†<!-- -->,z)</strong> to create a readout geometry in the cylindrical coordinates with a segmentation of (24,24,24) in (r,<!-- -->Ï†<!-- -->,z). The model is conditonned on the energy of the incident particle. In this training, the incident energies are generated in a continious range from 1 GeV to 100 GeV. </p><p>The next training consisted of increasing the granularity of the segmentation. In fact, the <strong>(r,<!-- -->Ï†<!-- -->,z)</strong> segementation is more granular than the previous datasets with 50,48,120 for r, <!-- -->Ï†<!-- --> and z respectively.  This demonstrates the learning potential of this model with a highly granular input.  The VAE model is trained on the same particle type and the calorimeter geometry as previously. The energy range is also extended to 500 GeV using discrete energy points.
The gif below shows the longitudinal profile for different energies going from 10 GeV to 500 GeV.</p><p><img src="/assets/images/LongProf_120_layers-49e92b2d141b41390214f9fa08fb1d4f.gif" width="917" height="666"></p><p>The gif below shows the transverse profile for different energies going from 10 GeV to 500 GeV.</p><p><img src="/assets/images/LateProf_120_layers-e303571f3cfc02d88e2694ca16347e6d.gif" width="927" height="666"></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="extrapolation-power">Extrapolation power<a class="hash-link" href="#extrapolation-power" title="Direct link to heading">â€‹</a></h4><p>One of the key features of a generative model is the capacity to infer distributions of unseen data points during the training. Unseen data points refer to showers originating from particle energies different from the range of training. In the figzres below we can see longitudinal and transverse profiles of 0.5 GeV and 600 GeV which are extrapolated values to the energy range of training (1GeV-500GeV).</p><p><img src="/assets/images/extrapolTest_05GeV-ed4b171706cbfab75fda066ebe07bfb5.png" width="2070" height="742"></p><p><img src="/assets/images/extrapolTest_600GeV-a0c0471d3e2e3168573da5d6317dc7f0.png" width="2070" height="772"></p><h3 class="anchor anchorWithStickyNavbar_mojV" id="energy-and-angle-conditioning">Energy and angle conditioning<a class="hash-link" href="#energy-and-angle-conditioning" title="Direct link to heading">â€‹</a></h3><p>The next step towards building a generalizable generative model is to condition on the indicent angle of incoming particles. For that, the calorimeter used is built using PBWO4 geometry with a segmentation of (24,24,24) in (r,<!-- -->Ï†<!-- -->,z). Discrete energy points are considered in the range from 1 GeV to 1 TeV. </p><p><img src="/assets/images/incident_angles_PBW04Geo-5a4bb6fc3876dedf6c6ca985fc71576f.png" width="1714" height="1214"></p><p>The angles range from 0<!-- -->Â°<!-- --> to 90<!-- -->Â°<!-- --> in a step of 10<!-- -->Â°<!-- --> corresponding to the arrows from yellow to blue as shown in the figure above.</p><p>The longitudinal and lateral profiles are shown in the next two plots where we can see a good agreement to the full simulation. </p><p><img src="/assets/images/LongProf_60GeV_0-5b27781de9317910fab259e1d5133b99.png" width="921" height="636"> | <img src="/assets/images/TransProf_60GeV_0-7c4f2fdbebd4aedd9f4f107c2b086025.png" width="921" height="636"></p><p>One of the important metrics of a fast simulation appraoch is the simulation time, where it can be demonstrated here as function of different energies and angles. It can be seen that with the full simulation the time icreases with the energy as more interactions are needed to be modeled. On the other hand, with the fast simulation, the time is constant. For 500 GeV we can have 180 speedup factor.</p><p><img src="/assets/images/simulationTime-a25ddc393a87295f1dca4a68d95ca7c9.png" width="1980" height="864"></p><p>More plots and details are available in this <strong><a href="https://gitlab.cern.ch/dasalama/ag_ml_sim/-/blob/agmlsim_test_Pb_Geo/Geant4MLFastSim_Par04/build/ValidationPlots.ipynb" target="_blank" rel="noopener noreferrer">notebook</a></strong>.</p><h2 class="anchor anchorWithStickyNavbar_mojV" id="multiple-geometries">Multiple geometries<a class="hash-link" href="#multiple-geometries" title="Direct link to heading">â€‹</a></h2><p>The model in this case is tasked to learn to reconstruct showers coming from different calorimeter geometries. At first, the model learns to reconstruct showers using two simplified geometries of lead-tungestate and silicon-tungestung. The model learns p(x|e,a,g), where <strong>(e,a,g)=(energy,angle,geometry)</strong> </p><h3 class="anchor anchorWithStickyNavbar_mojV" id="multi-task-learning">Multi-task learning<a class="hash-link" href="#multi-task-learning" title="Direct link to heading">â€‹</a></h3><p>In the multi-task learning, the model is trained on a fixed number of tasks (calorimeter geometries in our case) and it can be evaluated only on the same tasks. The multi-task VAE model is trained on showers coming from the two simplified geometries lead-tungestate (PBW04) and silicon-tungestung (SiW). This conditional VAE model of this step is used to demonstrate how to use ML inference in Geant4. <strong><a href="https://gitlab.cern.ch/geant4/geant4/-/tree/master/examples/extended/parameterisations/Par04" target="_blank" rel="noopener noreferrer">Par04</a></strong> is a Geant4 example which demonstrates how to infer energies using the trained VAE model. More details on the example are given in <a href="/docs/G4_Inference/G4_examples">Geant4 section</a>.  </p><h3 class="anchor anchorWithStickyNavbar_mojV" id="meta-learning">Meta-learning<a class="hash-link" href="#meta-learning" title="Direct link to heading">â€‹</a></h3><p>Meta-learning is a learning to learn technique which takes a distribution of tasks, where each task corresponds to a learning problem with its set of examples, and it produces a quick learner which can generalize from small amounts of data examples. Model-agnostic meta-learning (<a href="https://arxiv.org/abs/1703.03400" target="_blank" rel="noopener noreferrer">MAML</a>) is a meta-learning algorithm which optimization problem is learning the initialization parameters (weights) of a neural network. These parameters constitute the <strong>meta-knowledge</strong> and their learning process is the <strong>meta-training step</strong>. They can be used as an initialization weights of the model and subsequently tuned on a new task. <a href="https://arxiv.org/abs/1803.02999" target="_blank" rel="noopener noreferrer">Reptile</a> is a first order gradient-based meta-learning algorithm, i.e. it performs stochastic gradient descent (SGD) on each task in a standard way as opposed to MAML which computes the second derivatives. This makes Reptile take less computations and memory, while the optimization problem remains the same as for MAML.</p><p>In this section, we show some results of <strong>MetaHEP</strong>, the first application of the meta-learning approach to accelerate shower simulation using very high granular data. The key idea behind a meta-learning approach is that instead of starting the training process from scratch on every new geometry, we can use the meta-knowledge for a faster and more data-efficient adaptation. This refers to learning from prior experience and using this step knowledge to guide the search of an optimal model for a new geometry. In our Reptile training loop, or meta-training, only two detector geometries of cylindrical SiW and SciPb are used to build the meta-knowledge. Tow remaining two geometries of cylindrical PBWO4 and SiW FCC-ee, one of the calorimeters proposed for the Future Circular Collider (FCC), a next generation of high performance particle colliders, are used to demonstrate the adaptation capabilities of the model. In order to compare between the full simulation (FullSim) and the fast simulation (MLSim), in this section, only the decoder network is used as a generator to perform inference after the adaptation step. The input inference vector is constructed by sampling from a d Gaussian distribution (where d is the dimension of the latent space). The condition vector comprises condition values of particle energy, entrance angle and detector identifier.</p><p>Let Î¸ denote the initial model parameters, and t a task from the set of tasks. In our case a task corresponds to learning to simulate showers from a single detector geometry. Different geometries correspond to different tasks. For a randomly sampled task t, the learning minimizes <strong>E<sub>t</sub>[L<sub>t</sub>(U<sup>k</sup><sub>t</sub>(<!-- -->Î¸<!-- -->))]</strong>, where L<sub>t</sub> represents the loss of the task t, k is the number of steps or updates and U denotes the updating operator such as gradient descent. Reptile is an iterative algorithm which starts by sampling a task from the distribution of tasks, trains on the task, and then moves weights of the model towards the trained weights. </p><p>The full simulation samples are showers of electrons generated with an energy range from 1 GeV to 1 TeV (in powers of 2) and angles from 50$\degree$ to 90<!-- -->Â°<!-- --> (in a step of 10<!-- -->Â°<!-- -->). Entrance angle of 90<!-- -->Â°<!-- -->means perpendicular to the z-axis. The used segmentation is (r,<!-- -->Ï†<!-- -->,z)=(18,50,45), i.e, each shower has 18x50x45 energies. Ten thousand particle showers are simulated for each primary particle energy and angle. In order to demonstrate that the model can learn from a small amount of datasets, only 30% of the available statistics (for each energy and angle) are used for the training. </p><h4 class="anchor anchorWithStickyNavbar_mojV" id="validation-on-a-meta-training-calorimeter-geometry">Validation on a meta-training calorimeter geometry<a class="hash-link" href="#validation-on-a-meta-training-calorimeter-geometry" title="Direct link to heading">â€‹</a></h4><p>Reptile is demonstrated to converge towards a solution Î¸ that is close (in Euclidean distance) to each task manifold of optimal solutions. This section demonstrates how the meta-knowledge can be applied on a meta-training task (geometry) and which can be fine tuned using few adaptation steps for a better performance. The below figures show the longitudinal profile for 64 (512) GeV particle with 90<!-- -->Â°<!-- -->entrance angle for the SiW geometry. Because this is one of the geometries that was used during the meta-learning step, one can see in the case where only the meta-knowledge is used (Step 0), there is fair agreement. After performing the adaption step with 100 steps, a better agreement is observed.  </p><p><img src="/assets/images/LongProf_E64_A90_0_100-45064c1daa6c2a2ae42f3337edd25c9c.png" width="1200" height="800"> | <img src="/assets/images/LongProf_E512_A90_0_100-a5b93342ad9ee6415d7647d1af7b6d5d.png" width="1200" height="800"></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="fast-adaptation-with-a-simplified-calorimeter-geometry">Fast adaptation with a simplified calorimeter geometry<a class="hash-link" href="#fast-adaptation-with-a-simplified-calorimeter-geometry" title="Direct link to heading">â€‹</a></h4><p>To test MetaHEP on a new calorimeter geometry, full simulation samples are generated using a lead tungstate (PBWO4) geometry with the same segmentation of (r,<!-- -->Ï†<!-- -->,z)=(18,50,45). The weights of the model are first initialized with the meta-knowledge and the adaptation step is tested for a 1000 steps with checkpoints every 10 steps. The adaptation progress is illustrated in the figures below, using the longitudinal profile distribution with 50 and 360 steps respectively. After 50 steps the generated longitudinal profile is in poor agreement with full simulation, but with 360 steps there is a very good agreement to the full simulation.</p><p><img src="/assets/images/LongProf_E64_A90_AdaStep_50-59ac3881e6943e4ce9e9b60b8dcee72a.png" width="1200" height="800"> | <img src="/assets/images/LongProf_E64_A90_AdaStep_360-d795cee986ebe3a9043e60762af93eff.png" width="1200" height="800"></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="adaptation-and-traditional-training">Adaptation and traditional training<a class="hash-link" href="#adaptation-and-traditional-training" title="Direct link to heading">â€‹</a></h4><p>The strength of the MetaHEP approach is best visible in comparison to a ``traditional&#x27;&#x27; training where a model starts the learning process from scratch. In the figure below, the longitudinal profile for the compared models using the same architecture and the same number of training/adaptation steps is illustrated. This shows that the adaptation step, after meta-training, can provide a faster solution to converge. A traditional training requires many more steps to converge. On top of that, the time to run 400 steps of adaptation is about 20.5s compared to 1200s for the same number of 400 steps of the traditional training on the same machine. around 3h for 3900 steps</p><p><img src="/assets/images/AdaptationVsTradTraining-377df9e4c6de49c819d8fd489ae57761.png" width="1208" height="844"></p><h4 class="anchor anchorWithStickyNavbar_mojV" id="fast-adaptation-with-a-real-calorimeter-geometry">Fast adaptation with a real calorimeter geometry<a class="hash-link" href="#fast-adaptation-with-a-real-calorimeter-geometry" title="Direct link to heading">â€‹</a></h4><p>The second test of MetaHEP capabilities is done on the SiW FCC-ee detector, which is very different from the other three detectors considered so far. As it is a detector with realistic layout, it is much more complicated, and more importantly further from the detectors that were used in the training. For the adaptation to this fourth detector, the weights of the model are first initialized with the meta-knowledge and the adaptation step is tested every 10 steps up to 2000 adaptation steps. Compared to the idealised PbWO4 calorimeter, the number of adaptation steps to get a very good agreement with the full simulation is almost 3 times higher. The main origin of this difference is justified by the fact that it is a more complex geometry, and further from the detectors used for training, therefore more steps are needed. In fact, the figures below show that with 1000 steps of adaptation the model is able to well reproduce the longitudinal and the lateral profiles. </p><p><img src="/assets/images/FCC-ee_Long_E64_A90_1000-4e10157470d49ab8a8fd87654c6a5d1c.png" width="1500" height="1000">
<img src="/assets/images/FCC-ee_LatPro_E64_A90_1000-6f322fe344290b8a21ffd7ece852bd71.png" width="1500" height="1000"></p><p>To read more:</p><ul><li>Caruana, R. (1997). Multitask learning. Machine learning, 28(1), 41-75.</li><li>Naik, D. K., &amp; Mammone, R. J. (1992, June). Meta-neural networks that learn by learning. In <!-- -->[Proceedings 1992]<!-- --> IJCNN International Joint Conference on Neural Networks (Vol. 1, pp. 437-442). IEEE.</li><li>Finn, C., Abbeel, P., &amp; Levine, S. (2017, July). Model-agnostic meta-learning for fast adaptation of deep networks. In International conference on machine learning (pp. 1126-1135). PMLR.</li><li>Nichol, A., Achiam, J., &amp; Schulman, J. (2018). On first-order meta-learning algorithms. arXiv preprint arXiv:1803.02999.</li></ul></div><footer class="theme-doc-footer docusaurus-mt-lg"><div class="theme-doc-footer-edit-meta-row row"><div class="col"><a href="https://github.com/DalilaSalamani/ML4Sim_Documentation.git/docs/ML_Model/training.md" target="_blank" rel="noreferrer noopener" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_dcUD" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div><div class="col lastUpdated_foO9"></div></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Docs pages navigation"><div class="pagination-nav__item"><a class="pagination-nav__link" href="/docs/ml_workflow"><div class="pagination-nav__sublabel">Previous</div><div class="pagination-nav__label">Machine learning workflow</div></a></div><div class="pagination-nav__item pagination-nav__item--next"><a class="pagination-nav__link" href="/docs/ML_Model/optimization"><div class="pagination-nav__sublabel">Next</div><div class="pagination-nav__label">Model optimization</div></a></div></nav></div></div><div class="col col--3"><div class="tableOfContents_cNA8 thin-scrollbar theme-doc-toc-desktop"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#single-geometry" class="table-of-contents__link toc-highlight">Single geometry</a><ul><li><a href="#energy-conditioning" class="table-of-contents__link toc-highlight">Energy conditioning</a></li><li><a href="#energy-and-angle-conditioning" class="table-of-contents__link toc-highlight">Energy and angle conditioning</a></li></ul></li><li><a href="#multiple-geometries" class="table-of-contents__link toc-highlight">Multiple geometries</a><ul><li><a href="#multi-task-learning" class="table-of-contents__link toc-highlight">Multi-task learning</a></li><li><a href="#meta-learning" class="table-of-contents__link toc-highlight">Meta-learning</a></li></ul></li></ul></div></div></div></div></main></div></div><footer class="footer footer--dark"><div class="container container-fluid"><div class="row footer__links"><div class="col footer__col"><div class="footer__title">Docs</div><ul class="footer__items"><li class="footer__item"><a class="footer__link-item" href="/docs/intro">Get started</a></li></ul></div><div class="col footer__col"><div class="footer__title">Community</div><ul class="footer__items"><li class="footer__item"><a href="https://indico.cern.ch/category/13860/" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>ML4Sim<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li><li class="footer__item"><a href="https://mattermost.web.cern.ch/ml4sim/channels/town-square" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>Mattermost<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div><div class="col footer__col"><div class="footer__title">More</div><ul class="footer__items"><li class="footer__item"><a href="https://github.com/DalilaSalamani/ML4Sim_Documentation.git" target="_blank" rel="noopener noreferrer" class="footer__link-item"><span>GitHub<svg width="13.5" height="13.5" aria-hidden="true" viewBox="0 0 24 24" class="iconExternalLink_I5OW"><path fill="currentColor" d="M21 13v10h-21v-19h12v2h-10v15h17v-8h2zm3-12h-10.988l4.035 4-6.977 7.07 2.828 2.828 6.977-7.07 4.125 4.172v-11z"></path></svg></span></a></li></ul></div></div><div class="footer__bottom text--center"><div class="footer__copyright">Copyright Â© 2022, CERN</div></div></div></footer></div>
<script src="/assets/js/runtime~main.71701159.js"></script>
<script src="/assets/js/main.f9c432a9.js"></script>
</body>
</html>